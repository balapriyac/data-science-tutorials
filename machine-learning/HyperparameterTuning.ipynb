{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Start Simple â€“ Train a Baseline Model Without Any Tuning"
      ],
      "metadata": {
        "id": "i2Ju74quwU_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBt_HjnMv7Qf"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load data\n",
        "data = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=25)\n",
        "\n",
        "# Initialize model with default parameters\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "baseline_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Baseline Accuracy: {baseline_accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Use Hyperparameter Search with Cross-Validation"
      ],
      "metadata": {
        "id": "aEjaShhwwaC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load data\n",
        "data = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=25)\n",
        "\n",
        "# Initialize model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Define hyperparameter grid for Grid Search\n",
        "param_grid = {\n",
        "\t'criterion': ['gini', 'entropy'],\n",
        "\t'max_depth': [None, 10, 20, 30],\n",
        "\t'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Grid Search\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params_grid = grid_search.best_params_\n",
        "best_score_grid = grid_search.best_score_\n",
        "\n",
        "print(f'Best Parameters (Grid Search): {best_params_grid}')\n",
        "print(f'Best Cross-Validation Score (Grid Search): {best_score_grid:.2f}')"
      ],
      "metadata": {
        "id": "-KWQc3JpwfZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Use Randomized Search for Initial Exploration"
      ],
      "metadata": {
        "id": "qMMeeT_JwxHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "data = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=25)\n",
        "\n",
        "# Initialize model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Define hyperparameter distribution for Random Search\n",
        "param_dist = {\n",
        "\t'criterion': ['gini', 'entropy'],\n",
        "\t'max_depth': [None] + list(range(10, 31)),\n",
        "\t'min_samples_split': range(2, 11),\n",
        "\t'min_samples_leaf': range(1, 11)\n",
        "}\n",
        "\n",
        "# Random Search\n",
        "random_search = RandomizedSearchCV(model, param_dist, n_iter=100, cv=5, scoring='accuracy')\n",
        "random_search.fit(X_train, y_train)\n",
        "best_params_random = random_search.best_params_\n",
        "best_score_random = random_search.best_score_\n",
        "\n",
        "print(f'Best Parameters (Random Search): {best_params_random}')\n",
        "print(f'Best Cross-Validation Score (Random Search): {best_score_random:.2f}')\n",
        "\n",
        "best_model = DecisionTreeClassifier(**best_params_random)\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred = best_model.predict(X_test)\n",
        "final_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'Final Model Accuracy: {final_accuracy:.2f}')"
      ],
      "metadata": {
        "id": "TqNS89p_wyqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Monitor Overfitting with Validation Curves"
      ],
      "metadata": {
        "id": "Yu1VwYCnyCQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import validation_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define hyperparameter range\n",
        "param_range = [10, 100, 200, 400, 800, 1000]\n",
        "\n",
        "# Calculate validation curve\n",
        "train_scores, test_scores = validation_curve(\n",
        "\tRandomForestClassifier(), X_train, y_train,\n",
        "\tparam_name=\"n_estimators\", param_range=param_range,\n",
        "\tcv=5, scoring=\"accuracy\")\n",
        "\n",
        "# Calculate mean and standard deviation\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plot validation curve\n",
        "plt.plot(param_range, train_mean, label=\"Training score\", color=\"r\")\n",
        "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, color=\"r\", alpha=0.3)\n",
        "plt.plot(param_range, test_mean, label=\"Cross-validation score\", color=\"g\")\n",
        "plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, color=\"g\", alpha=0.3)\n",
        "plt.title(\"Validation Curve with Random Forest\")\n",
        "plt.xlabel(\"Number of Estimators\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hO_wPZKFyFaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Use Bayesian Optimization for Efficient Search"
      ],
      "metadata": {
        "id": "zaIfeNuryKXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "TBi7DOstyNGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data\n",
        "data = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=25)\n",
        "\n",
        "# Initialize model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Define hyperparameter space for Bayesian Optimization\n",
        "param_space = {\n",
        "\t'criterion': ['gini', 'entropy'],\n",
        "\t'max_depth': [None] + list(range(10, 31)),\n",
        "\t'min_samples_split': (2, 10),\n",
        "\t'min_samples_leaf': (1, 10)\n",
        "}"
      ],
      "metadata": {
        "id": "NA2_2DUeyPiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian Optimization\n",
        "opt = BayesSearchCV(model, param_space, n_iter=32, cv=5, scoring='accuracy')\n",
        "opt.fit(X_train, y_train)\n",
        "best_params_bayes = opt.best_params_\n",
        "best_score_bayes = opt.best_score_\n",
        "\n",
        "print(f'Best Parameters (Bayesian Optimization): {best_params_bayes}')\n",
        "print(f'Best Cross-Validation Score (Bayesian Optimization): {best_score_bayes:.2f}')"
      ],
      "metadata": {
        "id": "ASnb3BUnySWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = DecisionTreeClassifier(**best_params_bayes)\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred = best_model.predict(X_test)\n",
        "final_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'Final Model Accuracy: {final_accuracy:.2f}')"
      ],
      "metadata": {
        "id": "i4yfsPExyWNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dmwUTtZlzcP0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}